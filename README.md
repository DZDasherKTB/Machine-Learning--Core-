# 🧠 *Machine Learning (Core)* — From Scratch to Mastery

Welcome to my personal journey through classical Machine Learning.  
This repository is both a **learning roadmap** and a **model zoo** — every model is implemented from scratch using **Python + NumPy**, with real datasets and intuitive explanations.

---

## 🔍 What You'll Find Here

Each module contains:
- **📘 Conceptual explanations**
- **🧮 Mathematical intuition**
- **🛠️ Code from scratch**
- **📊 Trained models on real-world datasets**

---

## 📂 Folder Structure

| Folder                  | Description |
|-------------------------|-------------|
| [`Linear_Regression`](./Linear_Regression)   | Gradient Descent, Cost Function, R² Score |
| [`Logistic_Regression`](./Logistic_Regression) | Sigmoid, Binary Classifier |
| [`KNN`](./KNN)                         | Distance Metrics, KNN Voting |
| [`Naive_Bayes`](./Naive_Bayes)         | Gaussian + Multinomial — IMDB, Spam Detection |
| [`Decision_Trees`](./Decision_Trees)   | Gini/Entropy, Tree building |
| [`Random_forest`](./Random_forest)     | Bagging, MNIST Classification |
| [`Boosting`](./Boosting)               | AdaBoost, Gradient Boost, XGBoost |
| [`Stacking`](./Stacking)               | Meta-models, Cross-Val Stacking |
| [`SVM`](./SVM)                         | Hinge Loss, Margin Maximization |
| [`Clustring`](./Clustring)             | KMeans, DBSCAN — IQ Clustering |
| [`Ensemble_Learning`](./Ensemble_Learning) | Voting, Blending |
| [`Learning_stage`](./Learning_stage)   | First Experiments, Linear Updates |

---

## 🧠 What You’ll Learn

- ✅ How ML models *actually* work inside  
- ✅ Building without scikit-learn (mostly)
- ✅ Why certain models suit certain problems  
- ✅ Plotting and evaluating boundaries, clusters, and regressions  

---

## 🔬 Real-World Datasets Covered

This repo features models trained on:

- 🧠 *IQ, Marks, CGPA, Placement & Package*  
- 🧬 *Diabetes, Stroke, Tumor, Breast Cancer*  
- 🎥 *IMDB Sentiment*, *Spam Classification*  
- 🏡 *Boston Housing*, *New Home Price*  
- 🛳️ *Titanic Survival Prediction*  
- 🐱 *Dog vs Cat Unsupervised Clustering*  
- ✏️ *MNIST Handwriting Recognition*  
- 🌊 *Wine Quality*, *Play Tennis*, *UShape*  
- 🚀 *NASA Airfoil Self-Noise*  
- 💰 *Company Profit Forecasting*  

---

## 🧩 Full Journey & Roadmap

1. **Linear Regression**  
   _Gradient Descent, R², Feature Scaling, Custom Updates_

2. **Logistic Regression**  
   _Sigmoid function, Multi-class, Accuracy/Precision_

3. **K-Nearest Neighbors**  
   _Distance Metrics, Voting Logic_

4. **Naive Bayes**  
   _Probability-Based Classifier — Gaussian + Multinomial_

5. **Decision Trees**  
   _Split Criteria, Manual Tree Building_

6. **Random Forest**  
   _Row + Feature Sampling, Tree Bagging_

7. **Boosting**  
   _AdaBoost, Gradient Boosting from Research Paper, XGBoost_

8. **SVM (Support Vector Machine)**  
   _Hinge Loss, Maximum Margin Classifier_

9. **Clustering**  
   _KMeans + DBSCAN from scratch — IQ & Dog/Cat use-cases_

10. **Ensemble Learning**  
    _Voting, Blending, Stacking, Meta-models_

---

## 🚀 For Learners

- Clone this repo  
- Start from [`Linear_Regression`](./Linear_Regression)  
- Run `.ipynb` or `.py` files step-by-step  
- Visualize, understand, build  
- Iterate & train on your own datasets  

---

## 📌 Why I Built This

This is my **self-curated learning curriculum**:

- 🚀 Learn deeply through intuition  
- 🧱 Build from scratch to understand internals  
- 🔬 Apply models to real datasets  
- ⏱️ Documented through consistent **10-hour daily grinds**

I believe anyone can master ML — not with just courses, but with consistent hands-on effort and intuition-driven learning.

---

## ✅ Completed Extras

- ✅ **FastAPI + Flask** backends for deployment (from WebDev journey)  
- ✅ **Deep Learning**: CNNs, RNNs, Transformers from scratch  
- ✅ **Live Demos** with Gradio and Plotly  
- ✅ **Real-Time Model Serving** (coming soon in a separate repo)

---

## 🤝 Want to Contribute?

- Fork this repo  
- Improve visualizations, add notebooks  
- Try adding your own dataset applications  
- PRs are welcome!

---

> _Stay consistent, stay curious — mastery is built from the core._
